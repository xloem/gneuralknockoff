#!/usr/bin/env nnet
# ###################################################
# authors       : Jean Michel Sellier
#                 Carl Mueller
#                 Karl Semich
# created       : 17 Mar. 2016, Cassibile (SR), Italy
# last modified : 29 Aug. 2022, Vermont, USA
# purpose       :  The purpose of the following
#                  example is to fit a curve given by
#                  three points.
#                  The curve is a quadratic
#                  polynomial
# ###################################################

# load a previously saved neural network
# TODO: translate this LOAD_NEURAL_NETWORK network.net

# definitions of neurons
# each neuron is implicitly given an ID starting at 1
# these IDS are only incremental if inputs are first and outputs are last
StartNodes
    CreateInput(1 None Identity)
    CreateHidden(4 Multiply Tanh)
    CreateOutput(1 Multiply Tanh)
EndNodes

# define the connections between neurons and their initial weights
StartConnections
    # syntax: Connect(output_neurons input_neurons weights)
    # the output of the output neurons is connected to the input
    # of the input neurons
    # neurons may be ID or {first_ID last_ID}
    # weights may be Randomize, WEIGHT or [WEIGHT1 WEIGHT2 ...]
    Connect(1 {2 5} Randomize)
    Connect({2 5} 6 Randomize)
EndConnections

# training data for supervised learning
StartData
    #    source    uses and flags
    Data(Immediate Training
    #    inputs  outputs
        [[0.15] [0.0225]]
        [[0.60] [0.36]]
        [[0.80] [0.64]] )
EndData

# space search for the weights
#WEIGHT_MINIMUM -2.5
#WEIGHT_MAXIMUM +2.5

# specify the error function for the training process
#ERROR_TYPE MSE

# optimization method for the training process
# general syntax: TRAINING_METHOD method values

# simulated annealing syntax: verbosity mmax nmax kbtmin kbtmax accuracy
# where:
# verbosity = ON/OFF
# mmax      = outer loop - number of effective temperature steps
# nmax      = inner loop - number of test configurations
# kbtmin    = effective temperature minimum
# kbtmax    = effective temperature maximum
# accuracy  = numerical accuracy
#TRAINING_METHOD SIMULATED_ANNEALING ON 25 25000 1.e-4 8.0 1.e-2

# random search syntax: verbosity nmax accuracy
# where:
# verbosity = ON/OFF
# nmax      = maximum number of random attempts
# accuracy  = numerical accuracy
# TRAINING_METHOD RANDOM_SEARCH ON 500 1.e-3

# gradient descent syntax: verbosity nxw maxiter gamma accuracy
# where:
# verbosity = ON/OFF
# nxw       = number of cells in one direction of the weight space
# maxiter   = maximum number of iterations
# gamma     = step size
# accuracy  = numerical accuracy
# TRAINING_METHOD GRADIENT_DESCENT ON 32 5000 0.01 1.e-6

# genetic algorithm syntax: verbosity nmax npop rate accuracy
# where:
# verbosity = ON/OFF
# nmax      = number of generations
# npop      = number of individuals per generation
# rate      = rate of change between one generation and the parent
# accuracy  = numerical accuracy
# TRAINING_METHOD GENETIC_ALGORITHM ON 2048 1024 0.1 1.e-4

# save the output of the network
StartData
    Data(Immediate Deployment ReadNoOutput
        0.0 0.05 0.10 0.15 0.20
        0.25 0.30 0.35 0.40 0.45
        0.50 0.55 0.60 0.65 0.70
        0.75 0.80 0.85 0.90 0.95
        1.0 ToFile "Results.nnx")

